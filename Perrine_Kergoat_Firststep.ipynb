{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49c017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.request as ur\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import ete3\n",
    "import upsetplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba4ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncbi = ete3.NCBITaxa()\n",
    "#ncbi.update_taxonomy_database()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0469c06",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f6268",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Score parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63261d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Parameters (name, default) :\n",
    "    while True :   \n",
    "        try:\n",
    "            y = input(f\"What coefficient for {name}? (by default: {default}) \")\n",
    "            if y ==  \"\" or y ==  \" \" :\n",
    "                y  =  default \n",
    "                print(f\"Valid value: {default}\")\n",
    "                break\n",
    "            if  0 <= float(y) <= 1 : \n",
    "                print(f\"Valid value: {y}\")\n",
    "                break\n",
    "            else :\n",
    "                print(\"Invalid value\") \n",
    "            continue\n",
    "        except :\n",
    "            print(\"Invalid value\") \n",
    "            continue\n",
    "    return(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a860743-3452-4fc3-ad60-12a4dc02412e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Score option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16dd119-04a9-40fc-911d-16fc14b871c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score_type () :\n",
    "    while True :   \n",
    "        try:\n",
    "            y = input(f\"What type of score ? addition = completeness + consistency or multiplication = completeness + consistency (by default: addition) \")\n",
    "            if y ==  \"addition\" or y ==  \"addition \" or y ==  \"Addition\" or y ==  \"Addition \" or y ==  \"ADDITION\" or y ==  \"ADDITION \" or y ==  \"\" or y == \" \":\n",
    "                y  =  \"addition\" \n",
    "                print(f\"Valid option: {y}\")\n",
    "                break\n",
    "            if  y ==  \"multiplication\" or y ==  \"multiplication \" or y ==  \"Multiplication\" or y ==  \"Multiplication \" or y ==  \"MULTIPLICATION\" or y ==  \"MULTIPLICATION \": \n",
    "                print(f\"Valid option: {y}\")\n",
    "                break\n",
    "            else :\n",
    "                print(\"Invalid value\") \n",
    "            continue\n",
    "        except :\n",
    "            print(\"Invalid value\") \n",
    "            continue\n",
    "    return(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e099e92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sigmoïde transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fbd956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Sigmoide(x, a):\n",
    "    return (1/(1 + np.exp((-x + 0.5)*int(a)))) # f(x)=((1)/(1+ℯ^(10*(-x+0.5))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b476cc2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scoring the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42ea52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def  Scoring (Data,  parameters, score_option):\n",
    "    \n",
    "    cons = float(parameters[0])   \n",
    "    part_cons = parameters[1]\n",
    "    fra_cons = parameters[2]\n",
    "    cont = parameters[3]\n",
    "    fra_inco = parameters[4]\n",
    "    part_inco = parameters[5]\n",
    "    \n",
    "    Data[\"prot_consistent_fit\"] = Data[\"prot_consistent\"] - Data[\"prot_consistent_partial\"] - Data[\"prot_consistent_fragment\"]\n",
    "    Data[\"prot_contamination_fit\"] = Data[\"prot_contamination\"] - Data[\"prot_contamination_partial\"] - Data[\"prot_contamination_fragment\"]\n",
    "    Data[\"prot_inconsistent_fit\"] = Data[\"prot_inconsistent\"] - Data[\"prot_inconsistent_partial\"] - Data[\"prot_inconsistent_fragment\"]\n",
    "\n",
    "    \n",
    "    score = list()\n",
    "    \n",
    "    for index, row in Data.iterrows(): \n",
    "        single = row[\"hog_single\"]\n",
    "        duplicated = row[\"hog_duplicated\"]\n",
    "        consistent = row[\"prot_consistent\"]\n",
    "        consistent_fit = row[\"prot_consistent_fit\"]\n",
    "        partial_cons = row[\"prot_consistent_partial\"]\n",
    "        fragmented_cons = row[\"prot_consistent_fragment\"]\n",
    "        contamination = row[\"prot_contamination\"]\n",
    "        frangmented_incons = row[\"prot_inconsistent_fragment\"]\n",
    "        partial_incons = row[\"prot_inconsistent_partial\"]\n",
    "        \n",
    "        completeness = single + duplicated \n",
    "        \n",
    "        consistency_plus = consistent_fit*cons + partial_cons*part_cons + fragmented_cons*fra_cons # ajouter signle et duplicated et pas besoin de faire - missing puisque deduit \n",
    "        consistency_minus = contamination*cont + frangmented_incons*fra_inco + partial_incons*part_inco \n",
    "        consistency = consistency_plus - consistency_minus\n",
    "        \n",
    "        if score_option == \"addition\":\n",
    "            score_tot = (completeness + consistency)/200\n",
    "        elif score_option == \"multiplication\":\n",
    "            score_tot = (completeness * consistency)/10000\n",
    "        \n",
    "        score_sigmo = Sigmoide(score_tot, sig_coef) # call  the sigmoïde coefficient given by the user \n",
    "        \n",
    "        score.append(score_sigmo)\n",
    "    \n",
    "    Data[\"Score\"] = score\n",
    "    \n",
    "    return (Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48229084-2ec4-4731-bcfe-dbeb82fdbed1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform a list column into a dataframe column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73300eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DF_colomn (z):\n",
    "    z.tolist()\n",
    "    colomn = pd.DataFrame(z)\n",
    "    colomn[\"index\"] = range(0, len(colomn), 1)\n",
    "    colomn = colomn.set_index(\"index\")\n",
    "    return(colomn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f40e7-0751-4b2e-a7db-9bc4771d74f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform a dataframe column into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0766188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Col_in_list (colname, dtframe): \n",
    "    n_list = np.unique(dtframe[colname])\n",
    "    n_list = list(n_list)\n",
    "    return(n_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368fdceb-3fe1-408e-9767-376b1ae50501",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add the species names in the column \"sc_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94957f02-e6a5-430c-9b6f-abdf60266026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_names (Data):\n",
    "    dic_names = ncbi.get_taxid_translator(Data[\"taxon_id\"])\n",
    "    names = list()\n",
    "\n",
    "    for index, row in Data.iterrows(): \n",
    "        t_id = row[\"taxon_id\"]\n",
    "        names.append(dic_names.get(t_id))\n",
    "        \n",
    "    Data[\"sc_name\"] = names\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1a7ef2-54b1-458f-8fe2-246b4cd949d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Find the best score of each species in a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1ee22-87f3-49e3-aec7-90fd7ae74133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Best_scores_per_dtbase (dtbase, dtframe):\n",
    "    \n",
    "    dtframe.sort_values('Score',ascending=False, inplace=True) \n",
    "    \n",
    "    l_dtbase_tax = list()\n",
    "    l_dtbase_scores = list()\n",
    "    l_tax_dtbase = list()\n",
    "    \n",
    "    keep_data1 = pd.DataFrame(columns = [dtframe.columns])\n",
    "    \n",
    "    for index, row in dtframe.iterrows():    # list taxon of the database and keep the score associated\n",
    "        if row[\"source_db\"] == dtbase:\n",
    "            l_dtbase_tax.append(row[\"taxon_id\"])\n",
    "            l_dtbase_scores.append(row[\"Score\"])\n",
    "            keep_data1.loc[index] = row.tolist()\n",
    "    \n",
    "    best_scores = pd.DataFrame(columns = [dtframe.columns])\n",
    "    \n",
    "    for index, row in keep_data1.iterrows():     # list only the best \n",
    "        if row[\"taxon_id\"] not in l_tax_dtbase:\n",
    "            best_scores.loc[index] = row.tolist()\n",
    "            l_tax_dtbase.append(row[\"taxon_id\"])\n",
    "    \n",
    "    return(best_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b4e86-a493-43e8-8b00-56ea371fafe5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Find the best database for each commun taxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148d9464-ec04-4a9b-a2bd-a023055e2b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Best_dtbase_per_taxon (b_s_dtbase_1, b_s_dtbase_2, b_s_dtbase_3, l_dtbase, result):\n",
    "    \n",
    "    l_tax_3dtbase = list()\n",
    "    dtbase_tax = pd.DataFrame(columns = [result.columns])\n",
    "\n",
    "                        #keep_data1.loc[index] = row.tolist()\n",
    "    \n",
    "    for index, row in b_s_dtbase_1.iterrows():     # find the commun taxons\n",
    "        if int(row[\"taxon_id\"]) in Col_in_list(\"taxon_id\", b_s_dtbase_2) and int(row[\"taxon_id\"]) in Col_in_list(\"taxon_id\", b_s_dtbase_3): \n",
    "            l_tax_3dtbase.append(int(row[\"taxon_id\"]))\n",
    "            dtbase_tax.loc[index] = row.tolist()\n",
    "\n",
    "    l_tax = [int(item) for item in l_tax_3dtbase]\n",
    "    l_tax_1 = l_tax.copy()\n",
    "    l_tax_2 = l_tax.copy()\n",
    "    l_tax_3 = l_tax.copy()\n",
    "     \n",
    "    common_tax_1 = pd.DataFrame(columns = result.columns)\n",
    "    common_tax_2 = pd.DataFrame(columns = result.columns)\n",
    "    common_tax_3 = pd.DataFrame(columns = result.columns)\n",
    "    \n",
    "    for index, row in dtbase_tax.iterrows(): # select the commun taxon in the first dtbase\n",
    "        if row[\"taxon_id\"] in l_tax_1:\n",
    "            common_tax_1.loc[index] = row.tolist()\n",
    "            l_tax_1.remove(row[\"taxon_id\"])\n",
    "\n",
    "    common_tax_1.sort_values(by = [\"taxon_id\"], inplace = True)\n",
    "    common_tax_1.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "    for index, row in b_s_dtbase_2.iterrows(): # select the commun taxon in the second dtbase\n",
    "        if row[\"taxon_id\"] in l_tax_2:\n",
    "            common_tax_2.loc[index] = row.tolist()\n",
    "            l_tax_2.remove(row[\"taxon_id\"])\n",
    "\n",
    "    common_tax_2.sort_values(by = [\"taxon_id\"], inplace = True)            \n",
    "    common_tax_2.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    for index, row in b_s_dtbase_3.iterrows(): # select the commun taxon in the third dtbase\n",
    "        if row[\"taxon_id\"] in l_tax_3:\n",
    "            common_tax_3.loc[index] = row.tolist()\n",
    "            l_tax_3.remove(row[\"taxon_id\"])\n",
    "\n",
    "    common_tax_3.sort_values(by = [\"taxon_id\"], inplace = True)\n",
    "    common_tax_3.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    best_dt_tax = pd.DataFrame(index = l_tax, columns = l_dtbase)\n",
    "    best_dt_tax = pd.concat([common_tax_1, common_tax_2], ignore_index=True)\n",
    "    best_dt_tax = pd.concat([best_dt_tax, common_tax_3], ignore_index=True)\n",
    "    best_dt_tax.sort_values(by = [\"taxon_id\", \"Score\"], inplace = True, ascending = [True, False]) \n",
    "    \n",
    "    iter_dt_tax = best_dt_tax.copy()\n",
    "    l_tax_4 = l_tax.copy()\n",
    "    \n",
    "    for index, row in iter_dt_tax.iterrows():\n",
    "        if row[\"taxon_id\"] in l_tax_4:\n",
    "            l_tax_4.remove(row[\"taxon_id\"])\n",
    "        else:\n",
    "            best_dt_tax.drop([index], axis=0, inplace=True)\n",
    "    \n",
    "    best_dt_tax.sort_values(by = [\"Score\"], inplace = True, ascending = False)\n",
    "    \n",
    "    tax_b_s = pd.DataFrame(columns =  [l_dtbase[2], l_dtbase[0], l_dtbase[1]])\n",
    "    tax_b_s[l_dtbase[2]] = common_tax_1[\"Score\"]\n",
    "    tax_b_s[l_dtbase[0]] = common_tax_2[\"Score\"]\n",
    "    tax_b_s[l_dtbase[1]] = common_tax_3[\"Score\"]\n",
    "    \n",
    "    max_score = tax_b_s.max(axis = 1)\n",
    "    max_score = [float(item) for item in max_score]\n",
    "    \n",
    "    max_dtbase = list()\n",
    "    \n",
    "    for index, row in tax_b_s.iterrows(): \n",
    "        if str(max_score[index]) == str(tax_b_s[l_dtbase[2]][index]):\n",
    "            max_dtbase.append(l_dtbase[2])\n",
    "        elif max_score[index] == tax_b_s[l_dtbase[0]][index]:\n",
    "            max_dtbase.append(l_dtbase[0])\n",
    "        elif max_score[index] == tax_b_s[l_dtbase[1]][index]:\n",
    "            max_dtbase.append(l_dtbase[1])\n",
    "    \n",
    "    tax_b_s[\"max_score\"] = max_score\n",
    "    tax_b_s[\"best_dtbase\"] = max_dtbase\n",
    "    tax_b_s[\"taxon_id\"] = common_tax_1[\"taxon_id\"]\n",
    "    \n",
    "    tax_b_s['diff_UP_Ens'] = tax_b_s['UniProt Reference Proteomes'] - tax_b_s['Ensembl']\n",
    "    tax_b_s['diff_UP_RS'] = tax_b_s['UniProt Reference Proteomes'] - tax_b_s['RefSeq']\n",
    "    tax_b_s['diff_Ens_RS'] = tax_b_s['Ensembl'] - tax_b_s['RefSeq']\n",
    "    \n",
    "    return (best_dt_tax, tax_b_s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a4acb-b679-4a35-9983-80b6e3950ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d94979-5a6c-4502-b1c0-0f317caa3ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3b731-bf91-4b99-baf8-2f065197c8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9b19af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# \"User interface\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d2d652",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Taxon id to study (and verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840efd6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Work with 1963758 and 1437183\n",
    "\n",
    "while True :   \n",
    "    try:\n",
    "        tax_id = input(\"What is the NCBI id of the taxa to analyze? \")\n",
    "        if len(ncbi.get_taxid_translator([tax_id])) != 0: \n",
    "            print(\"Valid taxon id\")\n",
    "            break\n",
    "        else :\n",
    "            print(\"Invalid taxon id\") \n",
    "        continue\n",
    "    except :\n",
    "        print(\"Invalid taxon id\") \n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5da418",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sigmoïde coefficient to score more or less thigher the species "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d690dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Either 8 or 10\n",
    "\n",
    "while True :   \n",
    "    try:\n",
    "        sig_coef = input(\"What coefficient for the sigmoïde transformation of scores? (8 or 10, 10 tighter than 8) \")\n",
    "        if sig_coef ==  \"\" or sig_coef ==  \" \" :\n",
    "            sig_coef  =  4 \n",
    "            print(f\"By default coeficient: {sig_coef}\")\n",
    "            break\n",
    "        if  int(sig_coef) == 4 or int(sig_coef) == 8 or int(sig_coef) == 10 : # voir pour adoucir avec 6 ou 4 \n",
    "            print(\"Valid value\")\n",
    "            break\n",
    "        else :\n",
    "            print(\"Invalid value\") \n",
    "        continue\n",
    "    except :\n",
    "        print(\"Invalid value\") \n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2afdb86-8df5-4922-bc36-385e8c8bc0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e4dd6a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parameters of score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e14d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# By default : (1, 0.5, 0.5, 0.8, 0.5, 0.5)\n",
    "\n",
    "score_option = Score_type()\n",
    "cons = Parameters(\"consistent proteome\", 1)\n",
    "part_cons = Parameters(\"partially consistent proteome\", 0.5)\n",
    "fra_cons = Parameters(\"fragmented consistent proteome\", 0.5)\n",
    "cont = Parameters(\"contamination\", 0.8)\n",
    "fra_inco = Parameters(\"fragmented and incomplete proteome\", 0.5)\n",
    "part_inco = Parameters(\"partial and incomplete proteome\", 0.5)\n",
    "parameters = (cons, part_cons, fra_cons, cont, fra_inco, part_inco)\n",
    "parameters = [float(x) for x in parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7379e4-3729-4f95-9522-f5184e150181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ec5e8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main - part 1 : scoring the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e3099",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# glires 314147  \n",
    "# mesagiospermae 1437183\n",
    "\n",
    "#adress = f\"http://localhost:8000/api/results/?taxon_ids={tax_id}\"\n",
    "\n",
    "#\n",
    "adress = f\"https://omark.omabrowser.org/api/results/?taxon_ids={tax_id}\"\n",
    "\n",
    "# Get the data \n",
    "data_row = ur.urlopen(adress)\n",
    "data_json = json.loads(data_row.read())\n",
    "Data = pd.DataFrame.from_dict(data_json)\n",
    "\n",
    "#Score the genomes of interest \n",
    "result = Scoring(Data, parameters, score_option)    \n",
    "\n",
    "Add_names(result)\n",
    "\n",
    "result.sort_values(by = [\"Score\"], ascending = False, inplace = True) \n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced60d51-333f-4705-8a80-bef2ab681e6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main - part 2 : finding the best database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27191873-d44e-49d1-9e9a-0719b7d6194a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_scores_Uniprot = Best_scores_per_dtbase(\"UniProt Reference Proteomes\", result)\n",
    "best_scores_Ensembl = Best_scores_per_dtbase(\"Ensembl\", result)\n",
    "best_scores_RefSeq = Best_scores_per_dtbase(\"RefSeq\", result)\n",
    "\n",
    "l_dtbase = Col_in_list(\"source_db\", result)\n",
    "\n",
    "best_database_full = Best_dtbase_per_taxon(best_scores_Uniprot, best_scores_Ensembl, best_scores_RefSeq, l_dtbase, result)\n",
    "\n",
    "best_database = best_database_full[0]\n",
    "comp_database = best_database_full[1]\n",
    "\n",
    "#best_database\n",
    "comp_database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8b3dd-bf71-4a5e-9e4f-2d8d93f8855b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_UP = [0] * len(comp_database)\n",
    "l_Ens = [0] * len(comp_database)\n",
    "l_RS = [0] * len(comp_database)\n",
    "thres = 0.05   # Tuckey fence \n",
    "\n",
    "for index, row in comp_database.iterrows():\n",
    "    if row[\"best_dtbase\"] == \"UniProt Reference Proteomes\": \n",
    "        l_UP[index] = True\n",
    "        if abs(row[\"diff_UP_Ens\"]) < thres:\n",
    "            l_Ens[index] = True\n",
    "        else:\n",
    "            l_Ens[index] = False\n",
    "        if abs(row[\"diff_UP_RS\"]) < thres: \n",
    "            l_RS[index] = True\n",
    "        else:\n",
    "            l_RS[index] = False\n",
    "    elif row[\"best_dtbase\"] == \"Ensembl\": \n",
    "        l_Ens[index] = True\n",
    "        if abs(row[\"diff_UP_Ens\"]) < thres:\n",
    "            l_UP[index] = True\n",
    "        else: \n",
    "            l_UP[index] = False\n",
    "        if abs(row[\"diff_Ens_RS\"]) < thres:\n",
    "            l_RS[index] = True\n",
    "        else:\n",
    "            l_RS[index] = False\n",
    "    elif row[\"best_dtbase\"] == \"RefSeq\":\n",
    "        l_RS[index] = True \n",
    "        if abs(row[\"diff_UP_RS\"]) < thres:\n",
    "            l_UP[index] = True\n",
    "        else:\n",
    "            l_UP[index] = False\n",
    "        if abs(row[\"diff_Ens_RS\"]) < thres: \n",
    "            l_Ens[index] = True\n",
    "        else:\n",
    "            l_Ens[index] = False \n",
    "\n",
    "\n",
    "arrays = [l_UP, l_Ens, l_RS]\n",
    "tuples = list(zip(*arrays))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=[\"UniProt\", \"Ensembl\", \"RefSeq\"])\n",
    "serie = pd.Series(index.value_counts(), index = index)\n",
    "\n",
    "from upsetplot import UpSet\n",
    "test = UpSet(serie, subset_size = \"count\", facecolor = \"#3db7e9ff\", show_counts = True).plot() #, show_percentages = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e4737-dea4-43fb-b46d-77ec597430f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "species_comp = pd.DataFrame()\n",
    "species_comp[\"taxon_id\"] = comp_database[\"taxon_id\"]\n",
    "Add_names(species_comp)\n",
    "species_comp[\"UP\"] = l_UP\n",
    "species_comp[\"Ens\"] = l_Ens\n",
    "species_comp[\"RS\"] = l_RS\n",
    "\n",
    "Ens_solo = dict()\n",
    "RefSeq_solo = dict()\n",
    "Uniprot_solo = dict()\n",
    "Ens_RefSeq = dict()\n",
    "Uniprot_Ens = dict()\n",
    "Uniprot_RefSeq = dict()\n",
    "\n",
    "l_diff_spe = pd.DataFrame(columns = species_comp.columns)\n",
    "\n",
    "for index, row in species_comp.iterrows():\n",
    "    if row[\"UP\"] == False or row[\"Ens\"]== False or row[\"RS\"] == False:\n",
    "        l_diff_spe.loc[index] = row.tolist()\n",
    "\n",
    "l_diff_spe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999fdee2-21d2-44ae-95b4-5df54956f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cricetulus = pd.DataFrame(columns = result.columns)\n",
    "mesocricetus = pd.DataFrame(columns = result.columns)\n",
    "rattus = pd.DataFrame(columns = result.columns)\n",
    "cricetulus_1 = pd.DataFrame(columns = result.columns)\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "    if row[\"taxon_id\"] == 10029:\n",
    "        cricetulus.loc[index] = row.tolist()\n",
    "    if row[\"taxon_id\"] == 10036:\n",
    "        mesocricetus.loc[index] = row.tolist()\n",
    "    if row[\"taxon_id\"] == 10116:\n",
    "        rattus.loc[index] = row.tolist()\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "    if row[\"taxon_id\"] == 10029:\n",
    "        cricetulus_1.loc[0] = row.tolist()\n",
    "\n",
    "        \n",
    "#10029 Cricetulus griseus \n",
    "#10036 Mesocricetus auratus \n",
    "#10116 Rattus norvegicus \n",
    "#pd.options.display.max_colwidth = 150\n",
    "#cricetulus_1\n",
    "cricetulus\n",
    "#mesocricetus\n",
    "#rattus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3cf24-d771-4869-969d-a2bce4323816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9829ff-7e8b-41ff-a0f5-9ed77d3838f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b613976-dcab-4da8-a4f0-dd0f8713556b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# liste des especes des catégories --> index des listes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1323bd8b-7900-4fa6-851b-671a36f654bd",
   "metadata": {},
   "source": [
    "# Main - part 3 : get the highest diversity for the species choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336bc41-33f1-4cde-9ee0-d5ae144b5cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Species_choice(starting_species, best_database, k):\n",
    "\n",
    "\n",
    "    tree = ncbi.get_topology(list(best_database[\"taxon_id\"]), intermediate_nodes=True)\n",
    "    tax2score = dict(zip(best_database.taxon_id, best_database.Score))\n",
    "    leaves_left = [str(x) for x in list(best_database[\"taxon_id\"])]\n",
    "    subnodes = set()\n",
    "\n",
    "    while len(starting_species) < k:\n",
    "        for species in starting_species:\n",
    "            if species in leaves_left:\n",
    "                leaves_left.remove(species)\n",
    "                node = tree&species\n",
    "                for ancestor in node.get_ancestors():\n",
    "                    subnodes.add(ancestor.name)\n",
    "        #print(subnodes)\n",
    "        #print(leaves_left)\n",
    "\n",
    "        tree = ncbi.get_topology(list(leaves_left), intermediate_nodes=True)\n",
    "        tree.convert_to_ultrametric()\n",
    "        dist= list()\n",
    "        mod_dist = float(0)\n",
    "        b_div = float(0)\n",
    "\n",
    "        for leaf in tree.iter_leaves():\n",
    "            for ancest in leaf.iter_ancestors():\n",
    "                if ancest.name in subnodes:\n",
    "                    br_l = tree.get_distance(leaf, ancest.name, topology_only = False)\n",
    "                    score_leaf = tax2score[int(leaf.name)] \n",
    "                    div = br_l * score_leaf\n",
    "                    if div > b_div:\n",
    "                        b_div = div\n",
    "                        select_spec = leaf.name\n",
    "                    break\n",
    "\n",
    "        starting_species.append(str(select_spec))\n",
    "    return(starting_species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c47fae-933c-486b-a482-e54beed10f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081079f-2649-4765-a1a3-34afe783c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre tous les noeuds parents des espèces selectionnees dans un set\n",
    "#pour les nouvelles especes ajoutter leurs parents \n",
    "#calcul des distances par rapport au plus proche noeud du set \n",
    "# garder en mémoire uniquement la meilleure distance dans la boucle qui recalcule toutes les dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416dcd11-b654-435f-a92f-60902c22dc31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "starting_taxon = [str(x) for x in list(best_database[\"taxon_id\"])]\n",
    "starting_species = [starting_taxon[0]]\n",
    "#starting_species=[\"10090\"]\n",
    "Species_choice(starting_species, best_database, k)\n",
    "\n",
    "print(starting_species)\n",
    "\n",
    "name_sel_species = ncbi.get_taxid_translator(starting_species)\n",
    "name_sel_species\n",
    "#mettre tous les noeuds parents des espèces selectionnees dans un set\n",
    "#pour les nouvelles especes ajoutter leurs parents \n",
    "#calcul des distances par rapport au plus proche noeud du set \n",
    "# garder en mémoire uniquement la meilleure distance dans la boucle qui recalcule toutes les dist \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69da5c-a310-42d9-9eed-001777dd5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifier que la starting specie est une feuille \n",
    "# vérifier qu'il y a des données pour les 3 dtbases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cc5c1-b8f4-40f1-a4cc-bfff2f019541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975a81c-865e-4ffd-8ff6-cdeba4095867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efaa6f82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46825aab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### CSV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e4dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_database.to_csv(\"/Users/perrinekergoat/Desktop/best_database.csv\")\n",
    "#comp_database.to_csv(\"/Users/perrinekergoat/Desktop/comp_database.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1655a28",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Graphical verification of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092ca20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_plot = result[\"Score\"]\n",
    "data_plot = data_plot.values.tolist()\n",
    "plt.plot(data_plot)\n",
    "plt.title('Vertebrate scores')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35379d2-5cd4-4b12-822a-8873a2173cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot = best_database[\"Score\"]\n",
    "data_plot = data_plot.values.tolist()\n",
    "plt.plot(data_plot)\n",
    "plt.title('Vertebrate scores')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc24ed8-576b-4d1a-99ab-104846850949",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Affichage graphique type OMark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163142e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def OMark_graph (data):\n",
    "    fig, axes = plt.subplots(2,1,figsize = (15,5))\n",
    "\n",
    "    data.plot.bar(y=['hog_single', 'hog_duplicated','hog_missing'], label=['Single', 'Duplicated', 'Missing'], color = ['#46bea1ff', '#cfee8eff','#ed1c5aff'], \n",
    "                    ylim=(0,100), width=1.0,  stacked=True, ax=axes[0],edgecolor='gray', lw=0.1, rasterized=True)\n",
    "\n",
    "    data.plot.bar(y=['prot_consistent_fit','prot_consistent_partial', 'prot_consistent_fragment', \n",
    "                               'prot_contamination_fit', 'prot_contamination_partial', 'prot_contamination_fragment',\n",
    "                               'prot_inconsistent_fit', 'prot_inconsistent_partial', 'prot_inconsistent_fragment',\n",
    "                               'prot_not_mapped'], label=['Consistent', '','','Contamination','','','Inconsistent','','','Unknown'],\n",
    "                    color =['#3db7e9ff','#3db7e9ff','#3db7e9ff','#e69f00ff','#e69f00ff','#e69f00ff','#8a5df1ff','#8a5df1ff','#8a5df1ff','#000000ff' ],\n",
    "                               edgecolor='white', lw=0.2, ylim=(0,100), width=1.0, stacked=True, ax=axes[1], rasterized=True)\n",
    "\n",
    "    xticks = axes[0].get_xaxis().set_visible(False)\n",
    "    xticks = axes[1].xaxis.get_major_ticks()\n",
    "    \n",
    "    axes[1].set_xticklabels(data['sc_name'].squeeze())#data['source_db'].squeeze()) \"Cricetulus\"\n",
    "\n",
    "    bars = axes[1].patches\n",
    "    hatches= ['','///','///','','///','///','','///','///','']\n",
    "    col = ['white', 'darkslategray', 'whitesmoke','white', 'darkslategray', 'whitesmoke','white', 'darkslategray', 'whitesmoke','white']\n",
    "    for index, bar  in enumerate(bars):\n",
    "        bar.set_hatch(hatches[index//len(data)])\n",
    "        bar.set_edgecolor(col[index//len(data)])\n",
    "\n",
    "    partial_patch = mpatches.Patch(facecolor='white',lw='0.1', hatch='///', edgecolor='darkslategray', label='Partial mapping', alpha=.99)\n",
    "    fragment_patch = mpatches.Patch(facecolor='darkslategray',lw='0.1', hatch='///', edgecolor='white', label='Fragments', alpha=.99)\n",
    "    custom_legend = [partial_patch,fragment_patch]\n",
    "    axes[0].legend(title='Completeness', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    axes[1].legend(title='Consistency', handles=axes[1].get_legend_handles_labels()[0]+custom_legend, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "\n",
    "    axes[1].set_xlabel('Species') #Cricetulus griseus\n",
    "    axes[0].set_ylabel('Proportion of conserved HOGs')\n",
    "    axes[1].set_ylabel('Proportion of proteomes')\n",
    "    axes[1].set_ylim(axes[1].get_ylim()[::-1])\n",
    "    axes[1].tick_params(axis='x',labelsize=10)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0.05)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aec1a4-6e2c-4e2b-82fb-675f6a32d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "result.sort_values(by = \"taxon_id\", inplace = True, ascending = True)\n",
    "best_database.sort_values(by = \"taxon_id\", inplace = True, ascending = True)\n",
    "\n",
    "#result.sort_index()\n",
    "\n",
    "#OMark_graph(result)\n",
    "\n",
    "#\n",
    "OMark_graph(best_database)\n",
    "\n",
    "#OMark_graph(cricetulus_1)\n",
    "#OMark_graph(mesocricetus)\n",
    "#OMark_graph(rattus)\n",
    "\n",
    "\n",
    "#10029 Cricetulus griseus \n",
    "#10036 Mesocricetus auratus \n",
    "#10116 Rattus norvegicus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8257ccc-a61b-4b85-951b-069287911e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6442848-2340-4997-ae69-8339a0421fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d24a9123",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set rows' index as taxonomic id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137bcef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data = Data.set_index(\"taxon_id\", drop = False)\n",
    "#Data\n",
    "\n",
    "#pas une bonne idée :  perturbe tout à cause des index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912362e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68aa69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d084439f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Brouilllons "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f898a6",
   "metadata": {},
   "source": [
    "Ensuite algo optimiser le chemin dans l'arbre --> NOA'S ARC PROBLEM \n",
    "\n",
    "ETE3 package: .gettopology et .convert_to_ultrametric\n",
    "\n",
    "faire avec greedy algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62499994-1980-4b5e-9f9e-637ab3087fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f1fac-b3be-4684-8b09-5c5cabc95f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35235c61-bb18-4151-9497-d511e5638194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    " \n",
    " \n",
    "print(\"Current Python Version-\", python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f21eac-76ff-41eb-9947-ff86903abb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423f2e1-4e1d-4c4c-92d2-3b1d66e495bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
